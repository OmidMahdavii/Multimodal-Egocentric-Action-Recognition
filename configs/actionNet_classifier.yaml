action: train # train or test
name: classify_emg_lstm
modality: ["RGB"] # modality used
early_fusion: False
total_batch: 128 # total batch size if training is done with gradient accumulation
batch_size: 32 # batch size for the forward
gpus: null # gpus adopted
resume_from: null # checkpoint directory
models_dir: null # directory containing all the models

num_iter: 7000 # number of training iterations with total_batch size
lr_steps: 5000 # steps before reducing learning rate
eval_freq: 50 # evaluation frequency

loss_weights:
  full: [0.14804072,0.36782724,0.35686135,0.41979482,0.3651026,0.6885049,0.91976999,0.90487091,1.07562318,1.64618951,1.93512808,1.72409559,1.90867986,1.85789459,2.03871158,0.56273369,0.50998811,1.56035467,0.54093638,0.46889225]
  sub4: [0.08919617,0.3209069,0.23934306,0.30882976,0.23834994,0.49949857,0.85734829,0.87033841,0.95737225,1.1488467,1.59562042,2.87211676,2.49749283,2.7353493,2.49749283,0.36587475,0.44186412,0.87033841,0.36587475,0.22794577]

dataset:
  annotations_path: action-net/data
  shift: D1-D1
  workers: 4
  features_name: save_actionNet
  RGB:
    data_path: null

models:
  RGB:
    model: LSTM
    kwargs: {}
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
  EMG:
    model: EMG_LSTM
    kwargs: {}
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7
  fusion:
    model: Early_Fusion
    kwargs: {}
    lr: 0.01
    sgd_momentum: 0.9
    weight_decay: 1e-7


